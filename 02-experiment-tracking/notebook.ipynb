{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Configure MLflow Tracking and Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "\n",
    "# store run metadata (metrics, parameters, tags, etc.) in a SQLite database file named \"mlflow.db\"\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# log your runs under an experiment called \"nyc-taxi-experiment\"\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'data\\yellow_tripdata_2023-01.parquet').sample(frac=0.01)\n",
    "df_val = pd.read_parquet(r'data\\yellow_tripdata_2023-02.parquet').sample(frac=0.01)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['duration'] = (df_copy['tpep_dropoff_datetime'] - df_copy['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "df_copy = df_copy.loc[(df_copy['duration'] >= 1) & (df_copy['duration'] <= 60)]\n",
    "df_train = df_copy[['PULocationID', 'DOLocationID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "df_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train_encoded, df_copy['duration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lr_model.predict(X_train)\n",
    "mean_squared_error(y_train, y_pred_train, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['duration'] = (df_val['tpep_dropoff_datetime'] - df_val['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "df_val = df_val.loc[(df_val['duration'] >= 1) & (df_val['duration'] <= 60)]\n",
    "\n",
    "y_val = df_val['duration'].values\n",
    "df_val = df_val[['PULocationID', 'DOLocationID']]\n",
    "X_val = encoder.transform(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = lr_model.predict(X_val)\t\n",
    "mean_squared_error(y_val, y_pred_val, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump((lr_model, encoder), 'models/lin_reg.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.001).fit(X_train, y_train)\n",
    "y_pred_val = lasso.predict(X_val)\t\n",
    "mean_squared_error(y_val, y_pred_val, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### MLflow Run: Track Lasso Regression Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start a new run\n",
    "with mlflow.start_run():\n",
    "\n",
    "\tmlflow.set_tag('data-scientist', 'mohamed')\n",
    "\t\n",
    "\tmlflow.log_param('train-data-path', r'data\\yellow_tripdata_2023-01.parquet')\n",
    "\tmlflow.log_param('val-data-path', r'data\\yellow_tripdata_2023-02.parquet')\n",
    "\t\n",
    "\talpha = 0.1\n",
    "\tmlflow.log_param(\"alpha\", alpha)\n",
    "\tlasso = Lasso(alpha).fit(X_train, y_train)\n",
    "\t\n",
    "\ty_pred_val = lasso.predict(X_val)\t\n",
    "\trmse = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "\tmlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with Hyperopt + XGBoost\n",
    "\n",
    "| Term              | What it is                              | What it stands for / does                       |\n",
    "| ----------------- | --------------------------------------- | ----------------------------------------------- |\n",
    "| `fmin`            | Optimization function                   | Runs the tuning loop                            |\n",
    "| `tpe`             | Algorithm                               | Tree-structured Parzen Estimator (Bayesian opt) |\n",
    "| `hp`              | Hyperparameter search space constructor | Defines what values to try                      |\n",
    "| `STATUS_OK`       | Status flag                             | Tells Hyperopt the trial succeeded              |\n",
    "| `Trials`          | Trial tracker                           | Stores all results and parameter combinations   |\n",
    "| `scope`           | Type-caster                             | Converts floats to int, wraps Python functions  |\n",
    "\n",
    "We're importing the entire stack for **automated, intelligent hyperparameter tuning** using **Bayesian optimization** with **XGBoost**. Each piece is a cog in the tuning machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "val = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Steps of objective function:\n",
    "\n",
    "- Receive hyperparameters\n",
    "\n",
    "- Train the model\n",
    "\n",
    "- Return a loss value (e.g., RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\twith mlflow.start_run():\n",
    "\t\tmlflow.set_tag('model', 'xgboost')\n",
    "\t\tmlflow.log_params(params)\n",
    "\t\tbooster = xgb.train(\n",
    "\t\t\t   params=params, \n",
    "\t\t\t   dtrain=train, \n",
    "\t\t\t   num_boost_round=100, \n",
    "\t\t\t   evals=[(val, 'validation')], \n",
    "\t\t\t   early_stopping_rounds=50, \n",
    "\t\t\t   verbose_eval=False\n",
    "\t\t)\n",
    "\t\ty_pred = booster.predict(val)\n",
    "\t\trmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\t\tmlflow.log_metric('rmse', rmse)\n",
    "\t\treturn {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    # `quniform` produces discrete steps spaced by q from low to high: 3.0, 4.0, ..., 20.0\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 3, 20, 1)), \n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.3)), \n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1), # searches in this range: [exp(-6), exp(-1)] = [0.002, 0.368]\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1), \n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3), \n",
    "    'objective': 'reg:squarederror', \n",
    "    'seed': 42, \n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space, \n",
    "    algo=tpe.suggest, # guides the search intelligently\n",
    "    max_evals=50, # runs the objective function 50 times. Each time with a different set of parameters\n",
    "    trials=Trials() # stores results of all evaluations: parameters, loss, runtime, etc, so we can analyze or plot them later\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### [mlflow auto-logging](https://mlflow.org/docs/latest/tracking/autolog#:~:text=The%20following%20libraries%20support%20autologging%3A)\n",
    "\n",
    "`mlflow.xgboost.autolog()` must be called before training (e.g., `xgb.train(...)`) begins.\n",
    "\n",
    "**Best practice:** place `mlflow.xgboost.autolog()` outside of `mlflow.start_run()` at the very top of the script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "params = {\n",
    "    'colsample_bytree': 0.811456438126501,\n",
    "    'learning_rate': 0.23687492640963337,\n",
    "    'max_depth': 17,\n",
    "    'min_child_weight': 0.6041334208397435,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'reg_alpha': 0.05731229437746139,\n",
    "    'reg_lambda': 0.020764792800741835,\n",
    "    'seed': 42,\n",
    "    'subsample': 0.7453194874678659\n",
    "}\n",
    "\n",
    "booster = xgb.train(\n",
    "\tparams=params, \n",
    "\tdtrain=train, \n",
    "\tnum_boost_round=300, \n",
    "\tevals=[(val, 'validation')], \n",
    "\tearly_stopping_rounds=50, \n",
    "    verbose_eval=20\n",
    "\t# verbose_eval=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Logging models in mlflow\n",
    "\n",
    "-\t**Log as an artifact** (contains manual saving)\n",
    "\n",
    "\t```py\n",
    "\tmlflow.log_artifact(local_path=\"models/my_model.joblib\", artifact_path=\"joblib_models\")\n",
    "\t```\n",
    "\tThis tells MLflow to log `\"models/my_model.joblib\"` inside `\"mlruns/<current_exp_id>/<current_run_id>/artifacts/joblib_models\"`\n",
    "\n",
    "\tThe `artifact_path` is just a folder name inside the MLflow UI. If not provided, it will store it in `\"mlruns/<current_exp_id>/<current_run_id>/artifacts/\"`\n",
    "\n",
    "\tUse `mlflow.log_artifacts(local_dir=\"models\", artifact_path=)` for logging your models folder; if you just want to log a single file, use `mlflow.log_artifact()`\n",
    "\n",
    "<br>\n",
    "\n",
    "-\t**Log using `log_model` method** (more automatic; no manual saving)\n",
    "\n",
    "\t```python\n",
    "\tmlflow.<framework>.log_model(model, artifact_path=)\n",
    "\t```\n",
    "\tOr for custom pipelines:\n",
    "\t```python\n",
    "\tmlflow.pyfunc.log_model(python_model=YourCustomWrapper(...), artifact_path=)\n",
    "\t```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable now to avoid logging the model twice\n",
    "mlflow.xgboost.autolog(disable=True) \n",
    "\n",
    "with mlflow.start_run():\n",
    "\tbest_params = {\n",
    "\t\t'colsample_bytree': 0.811456438126501,\n",
    "\t\t'learning_rate': 0.23687492640963337,\n",
    "\t\t'max_depth': 17,\n",
    "\t\t'min_child_weight': 0.6041334208397435,\n",
    "\t\t'objective': 'reg:squarederror',\n",
    "\t\t'reg_alpha': 0.05731229437746139,\n",
    "\t\t'reg_lambda': 0.020764792800741835,\n",
    "\t\t'seed': 42,\n",
    "\t\t'subsample': 0.7453194874678659\n",
    "\t}\n",
    "\n",
    "\tmlflow.log_params(best_params)\n",
    "\n",
    "\tbooster = xgb.train(\n",
    "\t\tparams=best_params, \n",
    "\t\tdtrain=train, \n",
    "\t\tnum_boost_round=10, \n",
    "\t\tevals=[(val, 'validation')], \n",
    "\t\tearly_stopping_rounds=50, \n",
    "\t\tverbose_eval=20\n",
    "\t\t# verbose_eval=False\n",
    "\t)\n",
    "\n",
    "\ty_pred = booster.predict(val)\n",
    "\trmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\tmlflow.log_metric('rmse', rmse)\n",
    "\n",
    "\tjoblib.dump(encoder, \"models/encoder.joblib\")\n",
    "\tmlflow.log_artifact(\"models/encoder.joblib\", artifact_path=\"preprocessors\")\n",
    "\n",
    "\tmlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Loading models in mlflow\n",
    "\n",
    "-\t**Load model as a PyFuncModel**\n",
    "\n",
    "\t```py\n",
    "\tmlflow.pyfunc.load_model(logged_model_path)\n",
    "\t```\n",
    "\n",
    "-\t**Load model using its framework**\n",
    "\n",
    "\t```py\n",
    "\tmlflow.<framework>.load_model(logged_model_path)\n",
    "\t```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got this code snippet from mlflow ui\n",
    "logged_model = 'runs:/52594083daf440e3851dc88a08a3e62f/models_mlflow'\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = mlflow.xgboost.load_model(logged_model)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = booster.predict(val)\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Accesing the details from mlflow using the MLFlow client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids='1', \n",
    "    filter_string=\"metrics.rmse < 7.0\", \n",
    "    max_results=5, \n",
    "    order_by=['metrics.rmse ASC']\n",
    ")\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"Run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nyc-taxi-regressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_versions = client.get_latest_versions(model_name)\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, status: {version.tags['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.today().isoformat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.update_model_version(\n",
    "    name=model_name, \n",
    "    version=2, \n",
    "    description=f\"Model version 4 is updated at {datetime.today().isoformat(sep=' ')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Adding an MLflow Model to the Model Registry\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/TKHU7HAvGH8/maxresdefault.jpg\" alt=\"model registry\" width=\"800\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"7228072c97ea4e55a95204869efbb6cc\"\n",
    "model_uri = f\"runs:/{run_id}/models\"\n",
    "mlflow.register_model(model_uri=model_uri, name=model_name, tags={\"model\": \"RandomForest\", \"status\": \"staging\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
